{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction for Emotion Analysis\n",
    "### 1. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am just so bitter today</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yuck!So creepy</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Text  Emotion\n",
       "0  I am just so bitter today    anger\n",
       "1             yuck!So creepy  disgust"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Text': ['I am just so bitter today', 'yuck!So creepy'],\n",
    "     'Emotion': ['anger', 'disgust']}\n",
    "sample_data = pd.DataFrame(data=d)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unigram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(sample_data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names  ['am', 'bitter', 'creepy', 'just', 'so', 'today', 'yuck']\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature names \", count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 1 1 0]\n",
      " [0 0 1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.fit_transform(sample_data['Text']).toarray()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unigram & Bigram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names  ['am', 'am just', 'bitter', 'bitter today', 'creepy', 'just', 'just so', 'so', 'so bitter', 'so creepy', 'today', 'yuck', 'yuck so']\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "final_bigram_counts = count_vect.fit_transform(sample_data['Text'])\n",
    "print(\"Feature names \", count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names  ['am', 'bitter', 'creepy', 'just', 'so', 'today', 'yuck']\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer()\n",
    "TFIDF_data = tf_idf_vect.fit_transform(sample_data['Text'])\n",
    "print(\"Feature names \", tf_idf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47107781 0.47107781 0.         0.47107781 0.33517574 0.47107781\n",
      "  0.        ]\n",
      " [0.         0.         0.6316672  0.         0.44943642 0.\n",
      "  0.6316672 ]]\n"
     ]
    }
   ],
   "source": [
    "print(TFIDF_data.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bag of Words with SVD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am just so bitter today</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yuck! So creepy</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that's what I'm afraid of!</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh! You planned a surprise party for me!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When we give cheerfully and accept gratefully,...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The three R's depress me.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I don't talk about politics because people now...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No, We have stupid, dismal, lame winters where...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wow! What a beautiful wetehr today!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm getting so nervous for my first anatomy exam</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Eww! Why are spitting around?</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>easy, breezy, beautiful way</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text   Emotion\n",
       "0                           I am just so bitter today     anger\n",
       "1                                     yuck! So creepy   disgust\n",
       "2                          that's what I'm afraid of!      fear\n",
       "3            Oh! You planned a surprise party for me!  surprise\n",
       "4   When we give cheerfully and accept gratefully,...     happy\n",
       "5                           The three R's depress me.   sadness\n",
       "6   I don't talk about politics because people now...     anger\n",
       "7   No, We have stupid, dismal, lame winters where...   sadness\n",
       "8                 Wow! What a beautiful wetehr today!  surprise\n",
       "9    I'm getting so nervous for my first anatomy exam      fear\n",
       "10                      Eww! Why are spitting around?   disgust\n",
       "11                        easy, breezy, beautiful way     happy"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Text': \n",
    "     ['I am just so bitter today', \n",
    "      'yuck! So creepy',\n",
    "      \"that's what I'm afraid of!\",\n",
    "      \"Oh! You planned a surprise party for me!\",\n",
    "      \"When we give cheerfully and accept gratefully, everyone is blessed\",\n",
    "      \"The three R's depress me.\",\n",
    "      \"I don't talk about politics because people nowadays get offended easily!\",\n",
    "      \"No, We have stupid, dismal, lame winters where we maybe get some dangerous ice once.\",\n",
    "      \"Wow! What a beautiful wetehr today!\",\n",
    "      \"I'm getting so nervous for my first anatomy exam\",\n",
    "      \"Eww! Why are spitting around?\",\n",
    "      \"easy, breezy, beautiful way\"\n",
    "     ],\n",
    "     'Emotion': \n",
    "     ['anger', \n",
    "      'disgust',\n",
    "      'fear',\n",
    "      'surprise',\n",
    "      'happy',\n",
    "      'sadness',\n",
    "      'anger',\n",
    "      'sadness',\n",
    "      'surprise',\n",
    "      'fear',\n",
    "      'disgust',\n",
    "      'happy'\n",
    "     ]}\n",
    "sample_data = pd.DataFrame(data=d)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(sample_data['Text'])\n",
    "bow_counts = count_vect.fit_transform(sample_data['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_svd= decomposition.TruncatedSVD()\n",
    "t_svd.n_components = 2\n",
    "svd_data = t_svd.fit_transform(bow_counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data =  (12, 70)\n",
      "shape of truncated svd =  (12, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of train data = \", bow_counts.shape)\n",
    "print(\"shape of truncated svd = \", svd_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.46644039e-18  1.92392274e-15]\n",
      " [ 1.01739884e-15  9.33343749e-16]\n",
      " [-2.09512199e-16 -7.75860491e-16]\n",
      " [-1.47968094e-16  1.98593287e-15]\n",
      " [ 1.05391628e+00 -1.41421356e+00]\n",
      " [-8.31110955e-16  6.89392226e-16]\n",
      " [ 5.26958140e-01  2.82842712e+00]\n",
      " [ 4.03297502e+00 -2.53176598e-15]\n",
      " [ 5.21251528e-16  8.34277553e-16]\n",
      " [-4.86264367e-16  5.92103387e-15]\n",
      " [ 5.93909498e-17  1.20366455e-15]\n",
      " [ 3.68392992e-16  1.53436129e-16]]\n"
     ]
    }
   ],
   "source": [
    "print(svd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Classification for Emotion Analysis\n",
    "### 1. Bag of Words with Logistic Regression\n",
    "**Bag of Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(sample_data['Text'])\n",
    "final_counts = count_vect.fit_transform(sample_data['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rachel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lg = LogisticRegression()\n",
    "model_lg.fit(final_counts, sample_data['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disgust']\n"
     ]
    }
   ],
   "source": [
    "Y = count_vect.transform([\"you are sick\"])\n",
    "print(model_lg.predict(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sadness']\n"
     ]
    }
   ],
   "source": [
    "Y = count_vect.transform([\"no one cares\"])\n",
    "print(model_lg.predict(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF with Random Forest\n",
    "**TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer()\n",
    "TFIDF_data = tf_idf_vect.fit_transform(sample_data['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachel/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(TFIDF_data, sample_data['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fear']\n"
     ]
    }
   ],
   "source": [
    "Y = tf_idf_vect.transform([\"i am afraid of change\"])\n",
    "print(rf_clf.predict(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy']\n"
     ]
    }
   ],
   "source": [
    "Y = tf_idf_vect.transform([\"wow beautiful flowers\"])\n",
    "print(rf_clf.predict(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bag of Words with Neural Network\n",
    "[smartboost - Feature Classification for Emotion Analysis - Neural Network.ipynb](https://github.com/yingjie-dev/smartboost-opinion-mining/blob/master/smartboost%20-%20Feature%20Classification%20for%20Emotion%20Analysis%20-%20Neural%20Network.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
